
# **AI Web Summarizer**  
An AI-powered agent that extracts and summarizes key information from any given webpage.  

## **ğŸ”¹ Overview**  
This project is part of an **AI/ML intern assignment**, demonstrating expertise in **web scraping, NLP, embeddings, vector storage, and LLM-powered summarization**. The AI agent:  
- Accepts a **URL as input**  
- Scrapes and **cleans webpage content**  
- Converts text into **vector embeddings (FAISS)**  
- Retrieves **key information** using **semantic search**  
- Generates a **concise summary** using an LLM (Hugging Face API)  
- Provides a **user-friendly Streamlit UI**  

## **ğŸ”¹ Tech Stack & Libraries**  
| **Category** | **Tools & Libraries** |
|-------------|----------------------|
| **Web Scraping** | `requests`, `BeautifulSoup` |
| **Text Processing** | `langchain.text_splitter` |
| **Vector Storage & Retrieval** | `FAISS`, `sentence-transformers` |
| **Summarization (LLM)** | `transformers` (Mistral-7B via Hugging Face API) |
| **UI** | `streamlit` |
| **Environment Management** | `dotenv` (for API keys) |

---

## **ğŸ”¹ Project Structure**  

```plaintext
Zocket_Assgn01_Modified/
â”‚â”€â”€ app.py                # Streamlit UI for user interaction
â”‚â”€â”€ web_scraper.py        # Fetches and cleans webpage content
â”‚â”€â”€ vector_store.py       # Stores text in FAISS and retrieves key info
â”‚â”€â”€ summarizer.py         # Calls Hugging Face API for summarization
â”‚â”€â”€ .env                  # Stores API keys securely
â”‚â”€â”€ requirements.txt      # Lists all dependencies
â”‚â”€â”€ README.md             # Documentation for the project
```

---

## **ğŸ”¹ Setup & Installation**  

### **1ï¸âƒ£ Clone the Repository**  
```bash
git clone https://github.com/yourusername/Zocket_Assgn01_Modified.git
cd Zocket_Assgn01_Modified
```

### **2ï¸âƒ£ Install Dependencies**  
Ensure you have **Python 3.8+** installed. Then, install required packages:  
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Add Hugging Face API Key**  
Create a `.env` file and add your **Hugging Face API Key**:  
```plaintext
HUGGINGFACE_API_KEY=your_api_key_here
```

### **4ï¸âƒ£ Run the Streamlit App**  
```bash
streamlit run app.py
```

---

## **ğŸ”¹ How It Works**  

1ï¸âƒ£ **Web Scraping (`web_scraper.py`)**  
- Fetches webpage content using `requests` and `BeautifulSoup`.  
- Cleans and extracts **main article content** while removing irrelevant text.  

2ï¸âƒ£ **Vector Storage (`vector_store.py`)**  
- Splits text into **overlapping chunks** for better retention.  
- Converts text into **vector embeddings** using `sentence-transformers`.  
- Stores embeddings in **FAISS** for fast retrieval.  

3ï¸âƒ£ **Summarization (`summarizer.py`)**  
- Retrieves the **most relevant text chunks** from FAISS.  
- Calls **Mistral-7B (Hugging Face API)** to generate a **concise summary**.  

4ï¸âƒ£ **User Interface (`app.py`)**  
- Accepts a **URL** input from the user.  
- Displays extracted **key information** and **generated summary**.  

---



## **ğŸ”¹ Why This Project Stands Out?**  
âœ”ï¸ **Modular & Scalable** â€“ Each component (scraper, vector storage, summarization) is independent.  
âœ”ï¸ **Efficient Retrieval** â€“ Uses **semantic search** via FAISS instead of naive keyword matching.  
âœ”ï¸ **Latest AI Models** â€“ Uses **Mistral-7B**, a powerful LLM for summarization.  
âœ”ï¸ **Streamlit UI** â€“ Interactive and user-friendly interface for testing.  

---

## **ğŸ”¹ Future Improvements**  
ğŸ”¹ Improve **LLM more customised for Summary**  
ğŸ”¹ Add **memory retention** (e.g., storing past summaries).  
 
